{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkFiles\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import rand, col\n",
    "\n",
    "seed = 100\n",
    "sc = SparkContext()\n",
    "filePath = \"/home/jovyan/work/Personalization/ml-20m/ratings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset into spark RDD\n",
    "sc.addFile(filePath)\n",
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.csv(SparkFiles.get(\"ratings.csv\"), header=True, inferSchema=True)\n",
    "\n",
    "sqlContext.registerDataFrameAsTable(df, \"df\")\n",
    "df = sqlContext.sql('''\n",
    "    SELECT \n",
    "        userId AS user, \n",
    "        movieId AS item,\n",
    "        rating\n",
    "    FROM df\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(row, col):  (20000263, 4)\n"
     ]
    }
   ],
   "source": [
    "# adding uniform random numbers for train/validation/test set\n",
    "df = df.withColumn('TrainTest', rand(seed=seed))\n",
    "print(\"(row, col): \", (df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = df.where(col('TrainTest') < 0.75).drop(*[\"TrainTest\"])\n",
    "dftest = df.where(col('TrainTest') >= 0.75).drop(*[\"TrainTest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- item: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n",
      "None\n",
      "(row, col):  (15001032, 3)\n",
      "+----+----+------+\n",
      "|user|item|rating|\n",
      "+----+----+------+\n",
      "|   1|   2|   3.5|\n",
      "|   1|  29|   3.5|\n",
      "|   1|  32|   3.5|\n",
      "|   1|  47|   3.5|\n",
      "|   1| 112|   3.5|\n",
      "+----+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dftrain.printSchema())\n",
    "print(\"(row, col): \", (dftrain.count(), len(dftrain.columns)))\n",
    "dftrain.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- item: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n",
      "None\n",
      "(row, col):  (4999231, 3)\n",
      "+----+----+------+\n",
      "|user|item|rating|\n",
      "+----+----+------+\n",
      "|   1|  50|   3.5|\n",
      "|   1| 223|   4.0|\n",
      "|   1| 253|   4.0|\n",
      "|   1| 260|   4.0|\n",
      "|   1| 541|   4.0|\n",
      "+----+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dftest.printSchema())\n",
    "print(\"(row, col): \", (dftest.count(), len(dftest.columns)))\n",
    "dftest.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import operator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(nonnegative=True, checkpointInterval=3, coldStartStrategy=\"drop\")\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [5, 30, 70]) \\\n",
    "    .addGrid(als.regParam, [0.1, 1, 10]) \\\n",
    "    .build()\n",
    "\n",
    "rmse = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvs = TrainValidationSplit(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=rmse,\n",
    "    seed=seed,\n",
    "    trainRatio=0.66, # this ratio makes train:0.5 valid:0.25 and test:0.25\n",
    "    parallelism=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tvs.fit(dftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + '/ALS_model2'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+----------+\n",
      "|  user|item|rating|prediction|\n",
      "+------+----+------+----------+\n",
      "| 74757| 148|   3.5| 2.7267754|\n",
      "| 96393| 148|   3.0| 2.5813208|\n",
      "| 97435| 148|   4.0| 3.0522318|\n",
      "|136222| 148|   2.0|  2.585815|\n",
      "|137949| 148|   4.0| 3.1322215|\n",
      "| 19067| 148|   2.0| 1.5319937|\n",
      "| 87301| 148|   2.0|  2.642569|\n",
      "| 88527| 148|   2.0| 2.2116013|\n",
      "|108726| 148|   3.0| 2.6959863|\n",
      "|123246| 148|   3.0| 3.0632768|\n",
      "| 20132| 148|   3.0| 2.6023612|\n",
      "| 22884| 148|   3.0| 2.5250168|\n",
      "| 96427| 148|   3.0|  3.005178|\n",
      "| 10303| 148|   3.0|  2.884504|\n",
      "| 36821| 148|   4.0| 2.8097978|\n",
      "| 44979| 148|   3.0| 2.9125397|\n",
      "| 81218| 148|   1.0| 2.3467267|\n",
      "| 91782| 148|   3.0| 2.9503355|\n",
      "| 32882| 148|   3.0| 2.5714395|\n",
      "| 96884| 148|   4.0| 2.6100273|\n",
      "+------+----+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(dftrain).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+----------+\n",
      "| user|item|rating|prediction|\n",
      "+-----+----+------+----------+\n",
      "|53338| 148|   1.0| 2.5473833|\n",
      "|22684| 148|   4.0|  2.804213|\n",
      "|92852| 148|   3.0| 2.4693103|\n",
      "|83090| 148|   2.0| 1.9907694|\n",
      "|13170| 148|   3.0| 1.0899945|\n",
      "+-----+----+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testPred = model.transform(dftest)\n",
    "testPred.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8144994635502704"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse.evaluate(testPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
